## Real-time Sign Language Detection using Deep Learning
 
### Reference	Links

Google Slide Deck: https://docs.google.com/presentation/d/1z1PfkJE-RIYht83r8sTszaFSZNtkoV5wZTWuQjLnIhs/edit#slide=id.p12

Medium Blog Post: https://medium.com/@yashpreet.kaur_11815/real-time-sign-language-detection-system-e3dcb46854b0

Google Collab Python Code: https://colab.research.google.com/drive/17zf8ebH5k4wZabcIGxze1qbtJ6i8cHie?usp=sharing#scrollTo=QIXutbQMQXRB

### Overview
We built a real-time sign language detection system that leverages real-time object detection methods in computer vision to classify American sign language signs (letters) into English text. This work is important to help close the gap between businesses that canâ€™t communicate with deaf customers, by helping to provide the technology to do so.
In our work, we leverage the YOLOv4-tiny model to detect sign language inputs in image, video, and real-time formats. This work leverages transfer learning and has computational advantages in addition to accuracy and learning capabilities. Our results show that our model successfully works on images, videos, and real-time input forms. We then conclude by looking at current real-time sign language detection systems and the future of this work.
 
